{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMA 865, Individual Assignment 1\n",
    "\n",
    "Last Updated December 11, 2023.\n",
    "\n",
    "- [Jose, Chua]\n",
    "- [Student number]\n",
    "- [Date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Sentiment Analysis via the ML-based approach\n",
    "\n",
    "Download the “Product Sentiment” dataset from the course portal: sentiment_train.csv and sentiment_test.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.a. Loading and Prep\n",
    "\n",
    "Load, clean, and preprocess the data as you find necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import langdetect \n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n"
     ]
    }
   ],
   "source": [
    "#importing test and train data\n",
    "\n",
    "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "\n",
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning**\n",
    "1. Remove Duplicates\n",
    "2. Case normalization\n",
    "3. Removing punctuation\n",
    "4. Removing special characters\n",
    "5. Removing extra whitespace\n",
    "6. removing numbers \n",
    "7. Spell Checking\n",
    "8. Tokenization\n",
    "9. Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "                                               Sentence  Polarity\n",
      "71                                               #NAME?         1\n",
      "219                                              #NAME?         1\n",
      "814                                  I love this place.         1\n",
      "816                              The food was terrible.         0\n",
      "843                                    I won't be back.         0\n",
      "846                   I would not recommend this place.         0\n",
      "904                                              #NAME?         0\n",
      "1285                                      Great phone!.         1\n",
      "1407                                       Works great.         1\n",
      "1524                                      Works great!.         1\n",
      "1543                            Don't buy this product.         0\n",
      "1744  If you like a loud buzzing to override all you...         0\n",
      "1748                                      Does not fit.         0\n",
      "1778                              This is a great deal.         1\n",
      "1792                                       Great Phone.         1\n",
      "1892                   Excellent product for the price.         1\n",
      "1896                                       Great phone.         1\n",
      "2363                   Definitely worth checking out.           1\n"
     ]
    }
   ],
   "source": [
    "#checking for duplicates (train)\n",
    "\n",
    "duplicates = df_train[df_train['Sentence'].duplicated()]\n",
    "\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting duplicates\n",
    "\n",
    "df_train=df_train[df_train['Sentence'] != '#NAME?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "               Sentence  Polarity\n",
      "185  Not recommended.           0\n"
     ]
    }
   ],
   "source": [
    "#checking for duplicates (test)\n",
    "\n",
    "duplicates = df_test[df_test['Sentence'].duplicated()]\n",
    "\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sentence):\n",
    "  \n",
    "    # Case normalization\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    sentence = re.sub(f\"[{string.punctuation}]\", \"\", sentence)\n",
    "\n",
    "    # Replace special characters\n",
    "    sentence = unidecode(sentence)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "\n",
    "    # Remove numbers\n",
    "    sentence = re.sub(r\"\\d+\", \"\", sentence)\n",
    "\n",
    "    # Spell checking\n",
    "    sentence = str(TextBlob(sentence).correct())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # Stopword removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    critical_stopwords = {\n",
    "        \"not\", \"no\", \"nor\", \"never\",\n",
    "        \"but\", \"however\", \"yet\", \"though\", \"although\",\n",
    "        \"very\", \"too\", \"much\", \"more\", \"most\", \"few\", \"less\", \"least\",\n",
    "        \"all\", \"some\", \"any\", \"only\", \"every\", \"each\", \"none\",\n",
    "        \"if\", \"then\", \"when\", \"while\"\n",
    "    }\n",
    "    stop_words -= critical_stopwords\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Join tokens back to a string if needed\n",
    "    return tokens  # Return tokens or ' '.join(tokens) for a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence  Polarity\n",
      "0                                        [loved, place]         1\n",
      "1                                    [crust, not, good]         0\n",
      "2                          [not, taste, texture, nasty]         0\n",
      "3     [stopped, late, may, bank, holiday, rich, stev...         1\n",
      "4                      [selection, menu, great, prices]         1\n",
      "...                                                 ...       ...\n",
      "2395  [almost, all, songs, cover, girl, oldfashioned...         0\n",
      "2396  [most, annoying, thing, cover, girl, way, rite...         0\n",
      "2397  [unfortunately, cover, girl, example, hollywoo...         0\n",
      "2398  [nonlinear, narration, thus, many, flashbacks,...         1\n",
      "2399  [good, cinematography, also, makes, monica, be...         1\n",
      "\n",
      "[2396 rows x 2 columns]\n",
      "                                              Sentence  Polarity\n",
      "0    [good, commentary, today, love, undoubtedly, f...         1\n",
      "1    [people, first, times, film, making, think, ex...         1\n",
      "2    [very, popular, when, cinema, good, house, ver...         1\n",
      "3           [feelgood, film, felt, when, came, cinema]         1\n",
      "4    [northern, humour, positive, community, repres...         1\n",
      "..                                                 ...       ...\n",
      "595  [got, bored, watching, justice, large, take, c...         0\n",
      "596  [unfortunately, any, virtue, films, production...         0\n",
      "597                               [word, embarrassing]         0\n",
      "598                               [exceptionally, bad]         0\n",
      "599  [all, all, insult, ones, intelligence, huge, w...         0\n",
      "\n",
      "[600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply to df_train\n",
    "df_train['Sentence'] = df_train['Sentence'].apply(preprocess_text)\n",
    "\n",
    "# Apply to df_test\n",
    "df_test['Sentence'] = df_test['Sentence'].apply(preprocess_text)\n",
    "\n",
    "# Print processed DataFrames\n",
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.b. Modeling\n",
    "\n",
    "Use your favorite ML algorithm to train a classification model.  Don’t forget everything that we’ve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.c. Assessing\n",
    "\n",
    "Use the testing data to measure the accuracy and F1-score of your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Given the accuracy and F1-score of your model, are you satisfied with the results, from a business point of view? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Show five example instances in which your model’s predictions were incorrect. Describe why you think the model was wrong. Don’t just guess: dig deep to figure out the root cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feel free to use code as well to answer this question. Or not. Up to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
