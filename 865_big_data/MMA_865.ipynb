{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMA 865, Individual Assignment 1\n",
    "\n",
    "Last Updated December 11, 2023.\n",
    "\n",
    "- [Jose, Chua]\n",
    "- [Student number]\n",
    "- [Date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Sentiment Analysis via the ML-based approach\n",
    "\n",
    "Download the “Product Sentiment” dataset from the course portal: sentiment_train.csv and sentiment_test.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.a. Loading and Prep\n",
    "\n",
    "Load, clean, and preprocess the data as you find necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import langdetect \n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n"
     ]
    }
   ],
   "source": [
    "#importing test and train data\n",
    "\n",
    "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "\n",
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Polarity\n",
       "0                           Wow... Loved this place.         1\n",
       "1                                 Crust is not good.         0\n",
       "2          Not tasty and the texture was just nasty.         0\n",
       "3  Stopped by during the late May bank holiday of...         1\n",
       "4  The selection on the menu was great and so wer...         1\n",
       "5     Now I am getting angry and I want my damn pho.         0\n",
       "6              Honeslty it didn't taste THAT fresh.)         0\n",
       "7  The potatoes were like rubber and you could te...         0\n",
       "8                          The fries were great too.         1\n",
       "9                                     A great touch.         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning**\n",
    "1. Remove Duplicates\n",
    "2. Case normalization\n",
    "3. Removing punctuation\n",
    "4. Removing special characters\n",
    "5. Removing extra whitespace\n",
    "6. removing numbers \n",
    "7. Removing weird characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "                                               Sentence  Polarity\n",
      "71                                               #NAME?         1\n",
      "219                                              #NAME?         1\n",
      "814                                  I love this place.         1\n",
      "816                              The food was terrible.         0\n",
      "843                                    I won't be back.         0\n",
      "846                   I would not recommend this place.         0\n",
      "904                                              #NAME?         0\n",
      "1285                                      Great phone!.         1\n",
      "1407                                       Works great.         1\n",
      "1524                                      Works great!.         1\n",
      "1543                            Don't buy this product.         0\n",
      "1744  If you like a loud buzzing to override all you...         0\n",
      "1748                                      Does not fit.         0\n",
      "1778                              This is a great deal.         1\n",
      "1792                                       Great Phone.         1\n",
      "1892                   Excellent product for the price.         1\n",
      "1896                                       Great phone.         1\n",
      "2363                   Definitely worth checking out.           1\n"
     ]
    }
   ],
   "source": [
    "#checking for duplicates\n",
    "\n",
    "duplicates = df_train[df_train['Sentence'].duplicated()]\n",
    "\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates\n",
    "df_train=df_train[df_train['Sentence'] != '#NAME?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case normalization\n",
    "df_train['Sentence'] = df_train['Sentence'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove puncuation\n",
    "df_train['Sentence'] = df_train['Sentence'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing special characters\n",
    "df_train['Sentence'] = df_train['Sentence'].apply(unidecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing white spaces\n",
    "df_train['Sentence']=df_train['Sentence'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing numbers\n",
    "df_train['Sentence'] = df_train['Sentence'].apply(lambda x: re.sub(r'\\d+', '', x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell check\n",
    "\n",
    "def correct_spelling(sentence):\n",
    "    return str(TextBlob(sentence).correct())\n",
    "\n",
    "# apply the function to the 'Sentence' column\n",
    "\n",
    "df_train['Sentence'] = df_train['Sentence'].apply(correct_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "\n",
    "df_train['Sentence']=df_train['Sentence'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence  Polarity\n",
      "0                                        [loved, place]         1\n",
      "1                                    [crust, not, good]         0\n",
      "2                          [not, taste, texture, nasty]         0\n",
      "3     [stopped, late, may, bank, holiday, rich, stev...         1\n",
      "4                      [selection, menu, great, prices]         1\n",
      "...                                                 ...       ...\n",
      "2395  [almost, all, songs, cover, girl, oldfashioned...         0\n",
      "2396  [most, annoying, thing, cover, girl, way, rite...         0\n",
      "2397  [unfortunately, cover, girl, example, hollywoo...         0\n",
      "2398  [nonlinear, narration, thus, many, flashbacks,...         1\n",
      "2399  [good, cinematography, also, makes, monica, be...         1\n",
      "\n",
      "[2396 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#stoping\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "critical_stopwords = {\n",
    "    \"not\", \"no\", \"nor\", \"never\",\n",
    "    \"but\", \"however\", \"yet\", \"though\", \"although\",\n",
    "    \"very\", \"too\", \"much\", \"more\", \"most\", \"few\", \"less\", \"least\",\n",
    "    \"all\", \"some\", \"any\", \"only\", \"every\", \"each\", \"none\",\n",
    "    \"if\", \"then\", \"when\", \"while\"\n",
    "}\n",
    "\n",
    "stop_words -= critical_stopwords\n",
    "\n",
    "# Remove stopwords from tokenized lists\n",
    "\n",
    "df_train['Sentence'] = df_train['Sentence'].apply(\n",
    "    lambda tokens: [word for word in tokens if word.lower() not in stop_words]\n",
    ")\n",
    "\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.b. Modeling\n",
    "\n",
    "Use your favorite ML algorithm to train a classification model.  Don’t forget everything that we’ve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.c. Assessing\n",
    "\n",
    "Use the testing data to measure the accuracy and F1-score of your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Given the accuracy and F1-score of your model, are you satisfied with the results, from a business point of view? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Show five example instances in which your model’s predictions were incorrect. Describe why you think the model was wrong. Don’t just guess: dig deep to figure out the root cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feel free to use code as well to answer this question. Or not. Up to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
