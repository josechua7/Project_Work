{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMA 865, Individual Assignment 1\n",
    "\n",
    "Last Updated December 11, 2023.\n",
    "\n",
    "- [Jose, Chua]\n",
    "- [Student number]\n",
    "- [Date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Sentiment Analysis via the ML-based approach\n",
    "\n",
    "Download the “Product Sentiment” dataset from the course portal: sentiment_train.csv and sentiment_test.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.a. Loading and Prep\n",
    "\n",
    "Load, clean, and preprocess the data as you find necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.62.3)\n",
      "Requirement already satisfied: click in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2021.8.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.4)\n",
      "Requirement already satisfied: xgboost in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jose chua\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n"
     ]
    }
   ],
   "source": [
    "#importing test and train data\n",
    "\n",
    "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "\n",
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning**\n",
    "1. Remove Duplicates\n",
    "2. Case normalization\n",
    "3. Removing punctuation\n",
    "4. Removing special characters\n",
    "5. Removing extra whitespace\n",
    "6. removing numbers \n",
    "7. Spell Checking\n",
    "8. Tokenization\n",
    "9. Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "                                               Sentence  Polarity\n",
      "71                                               #NAME?         1\n",
      "219                                              #NAME?         1\n",
      "814                                  I love this place.         1\n",
      "816                              The food was terrible.         0\n",
      "843                                    I won't be back.         0\n",
      "846                   I would not recommend this place.         0\n",
      "904                                              #NAME?         0\n",
      "1285                                      Great phone!.         1\n",
      "1407                                       Works great.         1\n",
      "1524                                      Works great!.         1\n",
      "1543                            Don't buy this product.         0\n",
      "1744  If you like a loud buzzing to override all you...         0\n",
      "1748                                      Does not fit.         0\n",
      "1778                              This is a great deal.         1\n",
      "1792                                       Great Phone.         1\n",
      "1892                   Excellent product for the price.         1\n",
      "1896                                       Great phone.         1\n",
      "2363                   Definitely worth checking out.           1\n"
     ]
    }
   ],
   "source": [
    "#checking for duplicates (train)\n",
    "\n",
    "duplicates = df_train[df_train['Sentence'].duplicated()]\n",
    "\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting duplicates\n",
    "\n",
    "df_train=df_train[df_train['Sentence'] != '#NAME?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "               Sentence  Polarity\n",
      "185  Not recommended.           0\n"
     ]
    }
   ],
   "source": [
    "#checking for duplicates (test)\n",
    "\n",
    "duplicates = df_test[df_test['Sentence'].duplicated()]\n",
    "\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sentence):\n",
    "  \n",
    "    # Case normalization\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    sentence = re.sub(f\"[{string.punctuation}]\", \"\", sentence)\n",
    "\n",
    "    # Replace special characters\n",
    "    sentence = unidecode(sentence)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "\n",
    "    # Remove numbers\n",
    "    sentence = re.sub(r\"\\d+\", \"\", sentence)\n",
    "\n",
    "    # Spell checking\n",
    "    sentence = str(TextBlob(sentence).correct())\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # Stopword removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    critical_stopwords = {\n",
    "        \"not\", \"no\", \"nor\", \"never\",\n",
    "        \"but\", \"however\", \"yet\", \"though\", \"although\",\n",
    "        \"very\", \"too\", \"much\", \"more\", \"most\", \"few\", \"less\", \"least\",\n",
    "        \"all\", \"some\", \"any\", \"only\", \"every\", \"each\", \"none\",\n",
    "        \"if\", \"then\", \"when\", \"while\"\n",
    "    }\n",
    "    stop_words -= critical_stopwords\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Join tokens back to a string if needed\n",
    "    return tokens  # Return tokens or ' '.join(tokens) for a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence  Polarity\n",
      "0                                        [loved, place]         1\n",
      "1                                    [crust, not, good]         0\n",
      "2                          [not, taste, texture, nasty]         0\n",
      "3     [stopped, late, may, bank, holiday, rich, stev...         1\n",
      "4                      [selection, menu, great, prices]         1\n",
      "...                                                 ...       ...\n",
      "2395  [almost, all, songs, cover, girl, oldfashioned...         0\n",
      "2396  [most, annoying, thing, cover, girl, way, rite...         0\n",
      "2397  [unfortunately, cover, girl, example, hollywoo...         0\n",
      "2398  [nonlinear, narration, thus, many, flashbacks,...         1\n",
      "2399  [good, cinematography, also, makes, monica, be...         1\n",
      "\n",
      "[2396 rows x 2 columns]\n",
      "                                              Sentence  Polarity\n",
      "0    [good, commentary, today, love, undoubtedly, f...         1\n",
      "1    [people, first, times, film, making, think, ex...         1\n",
      "2    [very, popular, when, cinema, good, house, ver...         1\n",
      "3           [feelgood, film, felt, when, came, cinema]         1\n",
      "4    [northern, humour, positive, community, repres...         1\n",
      "..                                                 ...       ...\n",
      "595  [got, bored, watching, justice, large, take, c...         0\n",
      "596  [unfortunately, any, virtue, films, production...         0\n",
      "597                               [word, embarrassing]         0\n",
      "598                               [exceptionally, bad]         0\n",
      "599  [all, all, insult, ones, intelligence, huge, w...         0\n",
      "\n",
      "[600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply to df_train\n",
    "df_train['Sentence'] = df_train['Sentence'].apply(preprocess_text)\n",
    "\n",
    "# Apply to df_test\n",
    "df_test['Sentence'] = df_test['Sentence'].apply(preprocess_text)\n",
    "\n",
    "# Print processed DataFrames\n",
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.b. Modeling\n",
    "\n",
    "Use your favorite ML algorithm to train a classification model.  Don’t forget everything that we’ve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SVM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists in the 'Sentence' column into strings\n",
    "df_train['Sentence'] = df_train['Sentence'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "df_test['Sentence'] = df_test['Sentence'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target\n",
    "X_train = df_train['Sentence']\n",
    "y_train = df_train['Polarity']\n",
    "X_test = df_test['Sentence']\n",
    "y_test = df_test['Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify CountVectorizer to handle stopwords\n",
    "vectorizer = CountVectorizer(stop_words=None)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7533333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76       287\n",
      "           1       0.82      0.68      0.74       313\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.76      0.76      0.75       600\n",
      "weighted avg       0.76      0.75      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Create an instance of the SVM model\n",
    "svm_model = SVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform grid search\n",
    "grid_search.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.815937717466945\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters and corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.c. Assessing\n",
    "\n",
    "Use the testing data to measure the accuracy and F1-score of your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.7566666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78       287\n",
      "           1       0.85      0.65      0.73       313\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.77      0.76      0.75       600\n",
      "weighted avg       0.78      0.76      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_vec)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Test Set Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Given the accuracy and F1-score of your model, are you satisfied with the results, from a business point of view? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Show five example instances in which your model’s predictions were incorrect. Describe why you think the model was wrong. Don’t just guess: dig deep to figure out the root cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence  Actual  Predicted\n",
      "0  good commentary today love undoubtedly film wo...       1          1\n",
      "1  people first times film making think excellent...       1          1\n",
      "2  very popular when cinema good house very good ...       1          1\n",
      "3                feelgood film felt when came cinema       1          0\n",
      "4      northern humour positive community represents       1          1\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to compare predictions with actual values\n",
    "df_test_with_predictions = pd.DataFrame({\n",
    "    'Sentence': X_test,\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(df_test_with_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>fat computer week unbelievable bible thumped a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>only consistent thread holding series together...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>barely boring moment film plenty humorous parts</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>riot see hugo weaving play sexobsessed gay rea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>feelings thoughtsgabriels discomfort danceall ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Actual  Predicted\n",
       "307  fat computer week unbelievable bible thumped a...       0          1\n",
       "490  only consistent thread holding series together...       0          1\n",
       "242    barely boring moment film plenty humorous parts       1          0\n",
       "588  riot see hugo weaving play sexobsessed gay rea...       1          0\n",
       "433  feelings thoughtsgabriels discomfort danceall ...       1          0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the specific rows using the provided indices\n",
    "selected_rows = df_test_with_predictions.loc[[307, 490, 242, 588, 433]]\n",
    "\n",
    "# Display the selected rows\n",
    "selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
